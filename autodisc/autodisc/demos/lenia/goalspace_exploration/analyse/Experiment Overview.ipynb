{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import \n",
    "import autodisc as ad\n",
    "import ipywidgets\n",
    "import plotly\n",
    "import numpy as np\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define and load data\n",
    "org_experiment_definitions = [\n",
    "    # two dimensions\n",
    "    dict(id = '1',\n",
    "         directory = '../experiments/experiment_000001',\n",
    "         name = 'Test 1',\n",
    "         is_default = True),\n",
    "    dict(id = '2',\n",
    "         directory = '../experiments/experiment_000002',\n",
    "         name = 'Test 2',\n",
    "         is_default = True),\n",
    "]\n",
    "\n",
    "repetition_ids = list(range(10))\n",
    "\n",
    "# define names and load the data\n",
    "experiment_name_format = '<id> - <name>' # <id>, <name>\n",
    "\n",
    "experiment_definitions = []\n",
    "for org_exp_def in org_experiment_definitions:\n",
    "    new_exp_def = dict()\n",
    "    new_exp_def['directory'] = org_exp_def['directory']\n",
    "    if 'is_default' in org_exp_def:\n",
    "        new_exp_def['is_default'] = org_exp_def['is_default']\n",
    "    \n",
    "    if 'name' in org_exp_def:\n",
    "        new_exp_def['id'] = ad.gui.jupyter.misc.replace_str_from_dict(experiment_name_format, {'id': org_exp_def['id'], 'name': org_exp_def['name']})\n",
    "    else:\n",
    "        new_exp_def['id'] = ad.gui.jupyter.misc.replace_str_from_dict(experiment_name_format, {'id': org_exp_def['id']})\n",
    "\n",
    "    experiment_definitions.append(new_exp_def)\n",
    "\n",
    "experiment_statistics = dict()\n",
    "for experiment_definition in experiment_definitions:\n",
    "    experiment_statistics[experiment_definition['id']] = ad.gui.jupyter.misc.load_statistics(experiment_definition['directory'])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compute_running_average(data=None, data_sources=None, nsteps=50):\n",
    "    \n",
    "    averaged_data = dict()\n",
    "        \n",
    "    if not isinstance(data_sources, list):\n",
    "        data_sources = [data_sources]\n",
    "    \n",
    "    # compute for each experiment\n",
    "    for experiment_id, experiment_data in data.items():\n",
    "        \n",
    "        cur_average_experiment_data = dict()\n",
    "        \n",
    "        # compute for each given datasource\n",
    "        for datasource in data_sources:\n",
    "\n",
    "            # go through the sub elements of the current datasource to get to the final data\n",
    "            cur_data = experiment_data\n",
    "            \n",
    "            if not isinstance(datasource, tuple):\n",
    "                datasource = (datasource, )\n",
    "\n",
    "            # go though sub datasources to reach final data\n",
    "            for sub_ds in datasource:\n",
    "                cur_data = cur_data[sub_ds]\n",
    "\n",
    "            cur_average_data = np.zeros(cur_data.shape) * np.nan\n",
    "            \n",
    "            for end_idx in range(cur_data.shape[1]):\n",
    "                start_idx = max(0, end_idx - nsteps)\n",
    "                cur_average_data[:, end_idx] = np.nansum(cur_data[:, start_idx:end_idx+1], axis=1) / (end_idx-start_idx+1)\n",
    " \n",
    "            for sub_ds in reversed(datasource[1:]):\n",
    "                cur_average_data = {sub_ds: cur_average_data}\n",
    "            \n",
    "            cur_average_experiment_data[datasource[0]] = cur_average_data\n",
    "            \n",
    "        averaged_data[experiment_id] = cur_average_experiment_data\n",
    "            \n",
    "    return averaged_data\n",
    "\n",
    "# compute the running average for some statistics\n",
    "experiment_running_average_statisitics = compute_running_average(data=experiment_statistics, \n",
    "                                                                 data_sources=[('error_in_goalspace_between_goal_bestpolicy', 'data'),('error_in_goalspace_between_goal_usedpolicy', 'data')],\n",
    "                                                                 nsteps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error between Goal and Optimal Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PLOTTING\n",
    "config = dict(\n",
    "    layout = dict(\n",
    "        title = 'Error between Goal and Optimal Policy',\n",
    "        xaxis = dict(\n",
    "            title = 'explorations'\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title = 'error'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "elems = ad.gui.jupyter.interact_selection_multiple_experiments_repetitions(func=ad.gui.jupyter.plot_scatter_per_datasource, \n",
    "                                                            experiment_definitions=experiment_definitions,\n",
    "                                                            repetition_ids=repetition_ids, \n",
    "                                                            data=experiment_running_average_statisitics, \n",
    "                                                            data_source=('error_in_goalspace_between_goal_bestpolicy', 'data'), \n",
    "                                                            config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error between Goal and Used Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PLOTTING\n",
    "config = dict(\n",
    "    layout = dict(\n",
    "        title = 'Error between Goal and Used Policy',\n",
    "        xaxis = dict(\n",
    "            title = 'explorations'\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title = 'error'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "elems = ad.gui.jupyter.interact_selection_multiple_experiments_repetitions(func=ad.gui.jupyter.plot_scatter_per_datasource, \n",
    "                                                            experiment_definitions=experiment_definitions,\n",
    "                                                            repetition_ids=repetition_ids, \n",
    "                                                            data=experiment_running_average_statisitics, \n",
    "                                                            data_source=('error_in_goalspace_between_goal_usedpolicy', 'data'), \n",
    "                                                            config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Collect Data for categories\n",
    "\n",
    "# function to calcuate ratios\n",
    "def calc_binary_ratio(array):\n",
    "    return np.sum(array) / np.sum(~np.isnan(array))\n",
    "\n",
    "classifier_data = dict()\n",
    "for experiment_definition in experiment_definitions: \n",
    "\n",
    "    experiment_id = experiment_definition['id']\n",
    "    \n",
    "    dead_data = experiment_statistics[experiment_id]['classifier_dead']['data']\n",
    "    dead_ratio = experiment_statistics[experiment_id]['classifier_dead']['ratio']\n",
    "\n",
    "    animal_data = experiment_statistics[experiment_id]['classifier_animal']['data']\n",
    "    animal_ratio = experiment_statistics[experiment_id]['classifier_animal']['ratio']\n",
    "\n",
    "    non_animal_data = np.full(dead_data.shape, True)\n",
    "    non_animal_data[dead_data] = False\n",
    "    non_animal_data[animal_data] = False\n",
    "    non_animal_ratio = np.apply_along_axis(calc_binary_ratio, 1, non_animal_data)\n",
    "\n",
    "    diverging_data = np.full(experiment_statistics[experiment_id]['classifier_diverging']['data'].shape, True)\n",
    "    diverging_data[experiment_statistics[experiment_id]['classifier_diverging']['data'] == 0] = False\n",
    "    diverging_ratio = np.apply_along_axis(calc_binary_ratio, 1, diverging_data)\n",
    "    \n",
    "    diverging_animal_data = animal_data & diverging_data\n",
    "    diverging_animal_ratio = np.apply_along_axis(calc_binary_ratio, 1, diverging_animal_data)\n",
    "\n",
    "    non_diverging_animal_data = animal_data & ~diverging_data\n",
    "    non_diverging_animal_ratio = np.apply_along_axis(calc_binary_ratio, 1, non_diverging_animal_data)\n",
    "\n",
    "    diverging_non_animal_data = non_animal_data & diverging_data\n",
    "    diverging_non_animal_ratio = np.apply_along_axis(calc_binary_ratio, 1, diverging_non_animal_data)\n",
    "\n",
    "    non_diverging_non_animal_data = non_animal_data & ~diverging_data\n",
    "    non_diverging_non_animal_ratio = np.apply_along_axis(calc_binary_ratio, 1, non_diverging_non_animal_data)\n",
    "\n",
    "    non_diverging_animal_stable_fixpoint_data = non_diverging_animal_data & experiment_statistics[experiment_id]['classifier_stable_fixpoint_solution']['data']\n",
    "    non_diverging_animal_stable_fixpoint_ratio = np.apply_along_axis(calc_binary_ratio, 1, non_diverging_animal_stable_fixpoint_data) / non_diverging_animal_ratio\n",
    "    non_diverging_animal_stable_fixpoint_ratio[np.isnan(non_diverging_animal_stable_fixpoint_ratio)] = 0\n",
    "    \n",
    "    # animal & moving & not fixpoint\n",
    "    non_diverging_animal_moving_data = non_diverging_animal_data & experiment_statistics[experiment_id]['classifier_moving']['data'] & ~non_diverging_animal_stable_fixpoint_data\n",
    "    non_diverging_animal_moving_ratio = np.apply_along_axis(calc_binary_ratio, 1, non_diverging_animal_moving_data) / non_diverging_animal_ratio\n",
    "    non_diverging_animal_moving_ratio[np.isnan(non_diverging_animal_moving_ratio)] = 0\n",
    "    \n",
    "    # animal & not moving & not fixpoint\n",
    "    non_diverging_animal_non_moving_data = non_diverging_animal_data & ~experiment_statistics[experiment_id]['classifier_moving']['data'] & ~non_diverging_animal_stable_fixpoint_data\n",
    "    non_diverging_animal_non_moving_ratio = np.apply_along_axis(calc_binary_ratio, 1, non_diverging_animal_non_moving_data) / non_diverging_animal_ratio\n",
    "    non_diverging_animal_non_moving_ratio[np.isnan(non_diverging_animal_non_moving_ratio)] = 0\n",
    "    \n",
    "    non_diverging_non_animal_stable_fixpoint_data = non_diverging_non_animal_data & experiment_statistics[experiment_id]['classifier_stable_fixpoint_solution']['data']\n",
    "    non_diverging_non_animal_stable_fixpoint_ratio = np.apply_along_axis(calc_binary_ratio, 1, non_diverging_non_animal_stable_fixpoint_data) / non_diverging_non_animal_ratio\n",
    "    non_diverging_non_animal_stable_fixpoint_ratio[np.isnan(non_diverging_non_animal_stable_fixpoint_ratio)] = 0\n",
    "    \n",
    "    non_diverging_non_animal_non_stable_fixpoint_data = non_diverging_non_animal_data & ~experiment_statistics[experiment_id]['classifier_stable_fixpoint_solution']['data']\n",
    "    non_diverging_non_animal_non_stable_fixpoint_ratio = np.apply_along_axis(calc_binary_ratio, 1, non_diverging_non_animal_non_stable_fixpoint_data)  / non_diverging_non_animal_ratio\n",
    "    non_diverging_non_animal_non_stable_fixpoint_ratio[np.isnan(non_diverging_non_animal_non_stable_fixpoint_ratio)] = 0\n",
    "    \n",
    "    \n",
    "    classifier_data[experiment_id] = dict(     \n",
    "                            dead_data = dead_data,\n",
    "                            dead_ratio = dead_ratio,\n",
    "\n",
    "                            animal_data = animal_data,\n",
    "                            animal_ratio = animal_ratio,\n",
    "\n",
    "                            non_animal_data = non_animal_data,\n",
    "                            non_animal_ratio = non_animal_ratio,\n",
    "\n",
    "                            diverging_data = diverging_data,\n",
    "                            diverging_ratio = diverging_ratio,\n",
    "\n",
    "                            diverging_animal_data = diverging_animal_data,\n",
    "                            diverging_animal_ratio = diverging_animal_ratio,\n",
    "\n",
    "                            non_diverging_animal_data = non_diverging_animal_data,\n",
    "                            non_diverging_animal_ratio = non_diverging_animal_ratio,\n",
    "\n",
    "                            diverging_non_animal_data = diverging_non_animal_data,\n",
    "                            diverging_non_animal_ratio = diverging_non_animal_ratio,\n",
    "\n",
    "                            non_diverging_non_animal_data = non_diverging_non_animal_data,\n",
    "                            non_diverging_non_animal_ratio = non_diverging_non_animal_ratio,\n",
    "\n",
    "                            non_diverging_animal_stable_fixpoint_data = non_diverging_animal_stable_fixpoint_data,\n",
    "                            non_diverging_animal_stable_fixpoint_ratio = non_diverging_animal_stable_fixpoint_ratio,\n",
    "\n",
    "                            non_diverging_animal_moving_data = non_diverging_animal_moving_data,\n",
    "                            non_diverging_animal_moving_ratio = non_diverging_animal_moving_ratio,\n",
    "\n",
    "                            non_diverging_animal_non_moving_data = non_diverging_animal_non_moving_data,\n",
    "                            non_diverging_animal_non_moving_ratio = non_diverging_animal_non_moving_ratio,\n",
    "\n",
    "                            non_diverging_non_animal_stable_fixpoint_data = non_diverging_non_animal_stable_fixpoint_data,\n",
    "                            non_diverging_non_animal_stable_fixpoint_ratio = non_diverging_non_animal_stable_fixpoint_ratio,\n",
    "\n",
    "                            non_diverging_non_animal_non_stable_fixpoint_data = non_diverging_non_animal_non_stable_fixpoint_data,\n",
    "                            non_diverging_non_animal_non_stable_fixpoint_ratio = non_diverging_non_animal_non_stable_fixpoint_ratio\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Major Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plotting\n",
    "config = dict(\n",
    "    plot_type = 'plotly_box',\n",
    "    layout = dict(\n",
    "        title = 'Major Classification'\n",
    "        ),\n",
    "    trace_labels = ['dead', 'div non animal', 'div animal', 'non animal', 'animal'],\n",
    ")\n",
    "\n",
    "elems = ad.gui.jupyter.interact_selection_multiple_experiments_repetitions(func=ad.gui.jupyter.plot_barbox_per_datasource, \n",
    "                                                            experiment_definitions=experiment_definitions,\n",
    "                                                            repetition_ids=repetition_ids, \n",
    "                                                            data=classifier_data, \n",
    "                                                            data_source=['dead_ratio', 'diverging_non_animal_ratio', 'diverging_animal_ratio', 'non_diverging_non_animal_ratio', 'non_diverging_animal_ratio'],\n",
    "                                                            config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animal Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plotting\n",
    "config = dict(\n",
    "    plot_type = 'plotly_box',\n",
    "    layout = dict(\n",
    "        title = 'Animal Classification'\n",
    "        ),\n",
    "    trace_labels = ['stable fixpoint', 'moving', 'non moving'],\n",
    ")\n",
    "\n",
    "elems = ad.gui.jupyter.interact_selection_multiple_experiments_repetitions(func=ad.gui.jupyter.plot_barbox_per_datasource, \n",
    "                                                            experiment_definitions=experiment_definitions,\n",
    "                                                            repetition_ids=repetition_ids, \n",
    "                                                            data=classifier_data, \n",
    "                                                            data_source=['non_diverging_animal_stable_fixpoint_ratio', 'non_diverging_animal_moving_ratio', 'non_diverging_animal_non_moving_ratio'],\n",
    "                                                            config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Animal Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plotting\n",
    "config = dict(\n",
    "    plot_type = 'plotly_box',\n",
    "    layout = dict(\n",
    "        title = 'Non-Animal Classification'\n",
    "        ),\n",
    "    trace_labels = ['stable fixpoint', 'non stable'],\n",
    ")\n",
    "\n",
    "elems = ad.gui.jupyter.interact_selection_multiple_experiments_repetitions(func=ad.gui.jupyter.plot_barbox_per_datasource, \n",
    "                                                            experiment_definitions=experiment_definitions,\n",
    "                                                            repetition_ids=repetition_ids, \n",
    "                                                            data=classifier_data, \n",
    "                                                            data_source=['non_diverging_non_animal_stable_fixpoint_ratio', 'non_diverging_non_animal_non_stable_fixpoint_ratio'],\n",
    "                                                            config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plotting\n",
    "def plot_run_parameters_for_experiment(experiment_id):\n",
    "\n",
    "    config = dict(\n",
    "        subplots = dict(subplot_titles = ['R', 'T', 'm', 's', 'b:1', 'b:2', 'b:3', 'b:4'],\n",
    "                        rows=4,\n",
    "                        cols=2),\n",
    "        init_mode = 'elements',\n",
    "        layout = dict(\n",
    "            height = 1000,\n",
    "            default_xaxis = dict(\n",
    "                title = 'explorations'\n",
    "                ),\n",
    "            default_yaxis = dict(\n",
    "                title = 'error'\n",
    "                ),\n",
    "            ),\n",
    "        default_element_label = '<mean_label> - <subelem_idx>',\n",
    "        default_trace = dict(\n",
    "            mode = 'markers'\n",
    "            ),\n",
    "        default_mean_trace = dict(\n",
    "            legendgroup = '<data_idx>', # subplot_idx, data_idx\n",
    "            showlegend = False,\n",
    "            ),\n",
    "        default_subplot_mean_traces = [dict(\n",
    "            showlegend = True,\n",
    "            )],\n",
    "        default_element_trace = dict(\n",
    "            visible='legendonly',\n",
    "            legendgroup = 'elem <data_idx>-<subelem_idx>',\n",
    "            showlegend = False,\n",
    "            ),\n",
    "        default_subplot_element_traces = [dict(\n",
    "            showlegend = True\n",
    "            )],\n",
    "        default_data_element_traces = [dict(\n",
    "            visible = True\n",
    "            )]\n",
    "    )\n",
    "\n",
    "    ad.gui.jupyter.plot_scatter_per_datasource(experiment_ids=[experiment_id],\n",
    "                            repetition_ids=['all'], \n",
    "                            data=experiment_statistics, \n",
    "                            data_source=[('run_parameters','R'),\n",
    "                                         ('run_parameters','T'),\n",
    "                                         ('run_parameters','m'),\n",
    "                                         ('run_parameters','s'),\n",
    "                                         ('run_parameters','b', 0),\n",
    "                                         ('run_parameters','b', 1),\n",
    "                                         ('run_parameters','b', 2),\n",
    "                                         ('run_parameters','b', 3)], \n",
    "                            config=config)\n",
    "    \n",
    "experiment_ids = [exp_def['id'] for exp_def in experiment_definitions]    \n",
    "retval = ipywidgets.interact(plot_run_parameters_for_experiment, experiment_id = experiment_ids)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
