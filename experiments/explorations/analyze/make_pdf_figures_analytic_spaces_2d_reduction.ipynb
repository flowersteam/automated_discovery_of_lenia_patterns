{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D visualisation fo the analytic parameter and behavior space. (Fig. 22, 23 of supplementary material)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# default print properties\n",
    "multiplier = 2\n",
    "\n",
    "pixel_cm_ration = 36.5\n",
    "\n",
    "width_full = int(13.95 * pixel_cm_ration) * multiplier\n",
    "width_half = int(13.95/2 * pixel_cm_ration) * multiplier\n",
    "\n",
    "height_default_1 = int(3.5 * pixel_cm_ration) * multiplier\n",
    "height_default_2 = int(4.5 * pixel_cm_ration) * multiplier\n",
    "\n",
    "# margins in pixel\n",
    "top_margin = 0 * multiplier \n",
    "left_margin = 0 * multiplier \n",
    "right_margin = 0 * multiplier \n",
    "bottom_margin = 0 * multiplier \n",
    "\n",
    "font_size = 10 * multiplier \n",
    "font_family='Times New Roman'\n",
    "\n",
    "line_width = 2 * multiplier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Define and load data\n",
    "import autodisc as ad\n",
    "import ipywidgets\n",
    "import plotly\n",
    "import numpy as np\n",
    "import collections\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "data_filters = collections.OrderedDict()\n",
    "data_filters['dead'] = ('classifier_dead.data', '==', True)\n",
    "data_filters['non-animal'] = (('classifier_dead.data', '==', False), 'and', ('classifier_animal.data', '==', False))\n",
    "data_filters['animal'] = ('classifier_animal.data', '==', True)\n",
    "\n",
    "org_experiment_definitions = dict()\n",
    "\n",
    "org_experiment_definitions['main_paper'] = [\n",
    "     \n",
    "    dict(id = '1',\n",
    "         directory = '../experiments/experiment_000001',\n",
    "         name = 'Random',\n",
    "         is_default = True),\n",
    "\n",
    "    dict(id = '109',\n",
    "         directory = '../experiments/experiment_000109',\n",
    "         name = 'IMGEP-HGS',\n",
    "         is_default = True),\n",
    "    \n",
    "    dict(id = '202',\n",
    "         directory = '../experiments/experiment_000202',\n",
    "         name = 'IMGEP-PGL',\n",
    "         is_default = True),\n",
    "\n",
    "    dict(id = '302',\n",
    "         directory = '../experiments/experiment_000302',\n",
    "         name = 'IMGEP-OGL',\n",
    "         is_default = True),\n",
    "]\n",
    "\n",
    "repetition_ids = list(range(1))\n",
    "\n",
    "# define names and load the data\n",
    "experiment_name_format = '<name>' # <id>, <name>\n",
    "\n",
    "#global experiment_definitions\n",
    "experiment_definitions = []\n",
    "experiment_statistics = []\n",
    "\n",
    "current_experiment_list = 'main_paper'\n",
    "\n",
    "experiment_definitions = []\n",
    "for org_exp_def in org_experiment_definitions[current_experiment_list]:\n",
    "    new_exp_def = dict()\n",
    "    new_exp_def['directory'] = org_exp_def['directory']\n",
    "    if 'is_default' in org_exp_def:\n",
    "        new_exp_def['is_default'] = org_exp_def['is_default']\n",
    "\n",
    "    if 'name' in org_exp_def:\n",
    "        new_exp_def['id'] = ad.gui.jupyter.misc.replace_str_from_dict(experiment_name_format, {'id': org_exp_def['id'], 'name': org_exp_def['name']})\n",
    "    else:\n",
    "        new_exp_def['id'] = ad.gui.jupyter.misc.replace_str_from_dict(experiment_name_format, {'id': org_exp_def['id']})\n",
    "\n",
    "    experiment_definitions.append(new_exp_def)\n",
    "\n",
    "experiment_statistics = dict()\n",
    "for experiment_definition in experiment_definitions:\n",
    "    experiment_statistics[experiment_definition['id']] = ad.gui.jupyter.misc.load_statistics(experiment_definition['directory'])\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "run_parameter_space_dimensions = [\n",
    "    ('run_parameters', 'T'),\n",
    "    ('run_parameters', 'R'),\n",
    "    ('run_parameters', 'm'),\n",
    "    ('run_parameters', 's'),\n",
    "    ('run_parameters', 'b', 0),\n",
    "    ('run_parameters', 'b', 1),\n",
    "    ('run_parameters', 'b', 2),\n",
    "    ('parameter_initstate_space_representation','data','[0]'),\n",
    "    ('parameter_initstate_space_representation','data','[1]'),\n",
    "    ('parameter_initstate_space_representation','data','[2]'),\n",
    "    ('parameter_initstate_space_representation','data','[3]'),\n",
    "    ('parameter_initstate_space_representation','data','[4]'),\n",
    "    ('parameter_initstate_space_representation','data','[5]'),\n",
    "    ('parameter_initstate_space_representation','data','[6]'),\n",
    "    ('parameter_initstate_space_representation','data','[7]'),\n",
    "]\n",
    "\n",
    "statistic_space_dimensions = [\n",
    "    ('lenia_statistics','statistics.activation_mass[-1]'),\n",
    "    ('lenia_statistics','statistics.activation_volume[-1]'),\n",
    "    ('lenia_statistics','statistics.activation_density[-1]'),\n",
    "    ('lenia_statistics','statistics.activation_mass_asymmetry[-1]'),\n",
    "    ('lenia_statistics','statistics.activation_mass_distribution[-1]'),\n",
    "    ('statistic_space_representation','data','[0]'),\n",
    "    ('statistic_space_representation','data','[1]'),\n",
    "    ('statistic_space_representation','data','[2]'),\n",
    "    ('statistic_space_representation','data','[3]'),\n",
    "    ('statistic_space_representation','data','[4]'),\n",
    "    ('statistic_space_representation','data','[5]'),\n",
    "    ('statistic_space_representation','data','[6]'),\n",
    "    ('statistic_space_representation','data','[7]'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "## Compute PCA+UMAP per experiment repetition\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.preprocessing\n",
    "import collections\n",
    "import sklearn\n",
    "\n",
    "pca_algorithm = PCA(n_components=2)\n",
    "\n",
    "\n",
    "def get_statistic_space_points_of_repetition(experiment_definitions, source_data, space_defintion, data_filter=None):\n",
    "    '''\n",
    "    Collects for each exploration run the point in a defined space and constructs a matrix holding all points.\n",
    "    Collects this data for each experiment.\n",
    "    '''\n",
    "    \n",
    "    data_filter_inds = None\n",
    "    if data_filter is not None and data_filter:\n",
    "        # filter data according data_filter the given filter\n",
    "        data_filter_inds = ad.gui.jupyter.misc.filter_experiments_data(source_data, data_filter)\n",
    "    \n",
    "    data_statistic_space_points = dict() # {experiment-id} [repetition_idx, run_idx, space_dim_idx]\n",
    "    \n",
    "    for exp_def in experiment_definitions:\n",
    "        exp_id = exp_def['id']\n",
    "        \n",
    "        rep_data_matricies = []\n",
    "        \n",
    "        cur_data_filter_inds = data_filter_inds[exp_id] if data_filter_inds is not None else None  \n",
    "\n",
    "        # load data and define the bin_config\n",
    "        for dim_name in space_defintion:\n",
    "\n",
    "            # get all repetition data for the current parameter\n",
    "            try:\n",
    "                cur_data = ad.gui.jupyter.misc.get_experiment_data(data=source_data, experiment_id=exp_id, data_source=dim_name, repetition_ids='all', data_filter_inds=cur_data_filter_inds)\n",
    "                \n",
    "            except Exception as err:\n",
    "                if not isinstance(err, KeyError):\n",
    "                    raise Exception('Error during loading of data for Experiment {!r} (Datasource = {!r} )!'.format(exp_id, dim_name)) from err\n",
    "                else:\n",
    "                    # could not load data\n",
    "                    warnings.warn('Could not load data for Experiment {!r} (Datasource = {!r} )!'.format(exp_id, dim_name))\n",
    "                    cur_data = []\n",
    "            \n",
    "            # go over repetitions\n",
    "            for rep_idx, cur_rep_data in enumerate(cur_data):\n",
    "                cur_rep_data = np.array([cur_rep_data]).transpose()\n",
    "\n",
    "                if rep_idx >= len(rep_data_matricies):\n",
    "                    rep_data_matricies.append(cur_rep_data)\n",
    "                else:\n",
    "                    rep_data_matricies[rep_idx] = np.hstack((rep_data_matricies[rep_idx], cur_rep_data))\n",
    "        \n",
    "        data_statistic_space_points[exp_id] = dict()\n",
    "        data_statistic_space_points[exp_id]['statistic_space_points'] = np.array(rep_data_matricies)\n",
    "\n",
    "    return data_statistic_space_points\n",
    "\n",
    "\n",
    "def do_dimension_reduction(algorithm, space_dimensions, data_filter=None):\n",
    "    \n",
    "    # data_statistic_space_points:  {experiment-id}{'statistic_space_points'}[repetition_idx, run_idx, space_dim_idx]\n",
    "    data_statistic_space_points = get_statistic_space_points_of_repetition(experiment_definitions,\n",
    "                                                                           experiment_statistics,\n",
    "                                                                           space_dimensions,\n",
    "                                                                           data_filter=data_filter)\n",
    "    \n",
    "    # fit the umap models for each repetition on all the data of all experiments\n",
    "    umap_data = collections.defaultdict(lambda: dict()) # {experiment_id} {repetition_idx} ndarray[run_idx, dim_idx] \n",
    "        \n",
    "    for repetition_id in repetition_ids:\n",
    "\n",
    "        # collect the data of all experiments\n",
    "        all_experiment_data = None # ndarray[run_idx, dim_idx]\n",
    "\n",
    "        # (start_idx, end_idx) of the data in collected data the correspond to each experiment\n",
    "        data_idx_per_experiment = dict() # {experimend_id} (start_idx, end_idx)\n",
    "        \n",
    "        for exp_id, exp_data in data_statistic_space_points.items():\n",
    "\n",
    "            if all_experiment_data is None:\n",
    "                all_experiment_data = exp_data['statistic_space_points'][repetition_id,:,:]\n",
    "                start_idx = 0\n",
    "            else:\n",
    "                start_idx = all_experiment_data.shape[0]\n",
    "                all_experiment_data = np.vstack((all_experiment_data, exp_data['statistic_space_points'][repetition_id,:,:]))\n",
    "                \n",
    "            end_idx = all_experiment_data.shape[0] - 1\n",
    "            \n",
    "            data_idx_per_experiment[exp_id] = (start_idx, end_idx)\n",
    "\n",
    "        \n",
    "        all_experiment_data = sklearn.preprocessing.MinMaxScaler().fit_transform(all_experiment_data)\n",
    "        \n",
    "        all_experiment_data = np.nan_to_num(all_experiment_data)\n",
    "            \n",
    "        # fitt all data\n",
    "        embedded_data = algorithm.fit_transform(np.nan_to_num(all_experiment_data))\n",
    "        embedded_data = sklearn.preprocessing.MinMaxScaler().fit_transform(embedded_data)\n",
    "        \n",
    "        for exp_id in data_statistic_space_points.keys():\n",
    "            \n",
    "            start_idx = data_idx_per_experiment[exp_id][0]\n",
    "            end_idx = data_idx_per_experiment[exp_id][1]\n",
    "            \n",
    "            umap_data[exp_id][repetition_id] = embedded_data[start_idx:end_idx+1]\n",
    "                        \n",
    "    return umap_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# plot functions\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "    \n",
    "def plot_single_experiment(data, experiment_id, repetition_idx=0, experiment_statistics=None, data_filters=None, default_color='black', showlegend=True):  \n",
    "        \n",
    "    marker_color = ['rgb(0,0,0)', 'rgb(0,158,115)','rgb(230,159,0)', 'rgb(204,121,167)', 'rgb(0,114,178)', 'rgb(230,159,0)']\n",
    "    marker_symbol = ['circle', 'square', 'diamond']    \n",
    "    \n",
    "    plot_data = []\n",
    "    \n",
    "    if data_filters is None:\n",
    "        trace = plotly.graph_objs.Scatter(\n",
    "            x = data[experiment_id][repetition_idx][0:, 0],\n",
    "            y = data[experiment_id][repetition_idx][0:, 1],\n",
    "            mode = 'markers',\n",
    "            marker = dict(\n",
    "                color = default_color\n",
    "            )\n",
    "        )\n",
    "        plot_data.append(trace)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # go through filters\n",
    "        for filter_idx, (data_filter_name, data_filter) in enumerate(data_filters.items()):\n",
    "            \n",
    "            filter_inds = ad.gui.jupyter.misc.filter_single_experiment_data(experiment_statistics[experiment_id], data_filter, repetition_idx)\n",
    "            \n",
    "            trace = plotly.graph_objs.Scatter(\n",
    "                x = data[experiment_id][repetition_idx][filter_inds, 0],\n",
    "                y = data[experiment_id][repetition_idx][filter_inds, 1],\n",
    "                mode = 'markers',\n",
    "                name = data_filter_name,\n",
    "                marker = dict(\n",
    "                    color = marker_color[filter_idx],\n",
    "                    symbol = marker_symbol[filter_idx],\n",
    "                    size = 4,\n",
    "                )\n",
    "            )\n",
    "            plot_data.append(trace)\n",
    "            \n",
    "    # general layout of figure\n",
    "    layout = plotly.graph_objs.Layout(\n",
    "        xaxis=dict(\n",
    "            range=[-0.03,1.03],\n",
    "            showgrid=True,\n",
    "            zeroline=False,\n",
    "            showline=False,\n",
    "            ticks='',\n",
    "            showticklabels=False\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            range=[-0.03,1.03],\n",
    "            showgrid=True,\n",
    "            zeroline=False,\n",
    "            showline=False,\n",
    "            ticks='',\n",
    "            showticklabels=False\n",
    "        ),\n",
    "        font = dict(\n",
    "            family=font_family, \n",
    "            size=font_size, \n",
    "            ),\n",
    "        width=width_half, # in cm\n",
    "        height=height_default_2, # in cm\n",
    "        \n",
    "        margin = dict(\n",
    "            l=left_margin, #left margin in pixel\n",
    "            r=right_margin, #right margin in pixel\n",
    "            b=bottom_margin, #bottom margin in pixel\n",
    "            t=top_margin,  #top margin in pixel\n",
    "            ),        \n",
    "        \n",
    "        showlegend=showlegend,\n",
    "        legend=dict(\n",
    "            xanchor='left',\n",
    "            yanchor='bottom',\n",
    "            y=0,\n",
    "            x=0,\n",
    "            ), \n",
    "    )\n",
    "\n",
    "    fig = plotly.graph_objs.Figure(data=plot_data, layout=layout)\n",
    "\n",
    "    plotly.offline.iplot(fig)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# get data\n",
    "parameter_space_pca_data = do_dimension_reduction(pca_algorithm, run_parameter_space_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random')\n",
    "fig = plot_single_experiment(parameter_space_pca_data, \n",
    "                            experiment_id='Random',\n",
    "                            experiment_statistics=experiment_statistics, \n",
    "                            data_filters=data_filters,\n",
    "                            showlegend=False)\n",
    "print('IMGEP-HGS')\n",
    "fig = plot_single_experiment(parameter_space_pca_data, \n",
    "                            experiment_id='IMGEP-HGS',\n",
    "                            experiment_statistics=experiment_statistics, \n",
    "                            data_filters=data_filters,\n",
    "                            showlegend=False)\n",
    "\n",
    "print('IMGEP-PGL')\n",
    "fig = plot_single_experiment(parameter_space_pca_data, \n",
    "                            experiment_id='IMGEP-PGL',\n",
    "                            experiment_statistics=experiment_statistics, \n",
    "                            data_filters=data_filters,\n",
    "                            showlegend=True)\n",
    "print('IMGEP-OGL')\n",
    "fig = plot_single_experiment(parameter_space_pca_data, \n",
    "                            experiment_id='IMGEP-OGL',\n",
    "                            experiment_statistics=experiment_statistics, \n",
    "                            data_filters=data_filters,\n",
    "                            showlegend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistic Space -All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "statistic_space_all_pca_data = do_dimension_reduction(pca_algorithm, statistic_space_dimensions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random')\n",
    "fig = plot_single_experiment(statistic_space_all_pca_data, \n",
    "                            experiment_id='Random',\n",
    "                            experiment_statistics=experiment_statistics, \n",
    "                            data_filters=data_filters,\n",
    "                            showlegend=False)\n",
    "\n",
    "print('IMGEP-HGS')\n",
    "fig = plot_single_experiment(statistic_space_all_pca_data, \n",
    "                            experiment_id='IMGEP-HGS',\n",
    "                            experiment_statistics=experiment_statistics, \n",
    "                            data_filters=data_filters,\n",
    "                            showlegend=False)\n",
    "\n",
    "\n",
    "print('IMGEP-PGL')\n",
    "fig = plot_single_experiment(statistic_space_all_pca_data, \n",
    "                            experiment_id='IMGEP-PGL',\n",
    "                            experiment_statistics=experiment_statistics, \n",
    "                            data_filters=data_filters,\n",
    "                            showlegend=True)\n",
    "\n",
    "print('IMGEP-OGL')\n",
    "fig = plot_single_experiment(statistic_space_all_pca_data, \n",
    "                            experiment_id='IMGEP-OGL',\n",
    "                            experiment_statistics=experiment_statistics, \n",
    "                            data_filters=data_filters,\n",
    "                            showlegend=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "1014.85px",
    "left": "1786px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
